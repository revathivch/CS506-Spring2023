{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Worksheet 12\n",
    "\n",
    "Name:  Revathi Vipinachandran\n",
    "UID: U63888304\n",
    "\n",
    "### Topics\n",
    "\n",
    "- Naive Bayes\n",
    "- Model Evaluation\n",
    "\n",
    "### Naive Bayes\n",
    "\n",
    "| Attribute A | Attribute B | Attribute C | Class |\n",
    "|-------------|-------------|-------------|-------|\n",
    "| Yes         | Single      | High        | No    |\n",
    "| No          | Married     | Mid         | No    |\n",
    "| No          | Single      | Low         | No    |\n",
    "| Yes         | Married     | High        | No    |\n",
    "| No          | Divorced    | Mid         | Yes   |\n",
    "| No          | Married     | Low         | No    |\n",
    "| Yes         | Divorced    | High        | No    |\n",
    "| No          | Single      | Mid         | Yes   |\n",
    "| No          | Married     | Low         | No    |\n",
    "| No          | Single      | Mid         | Yes   |\n",
    "\n",
    "a) Compute the following probabilities:\n",
    "\n",
    "- P(Attribute A = Yes | Class = No)\n",
    "- P(Attribute B = Divorced | Class = Yes)\n",
    "- P(Attribute C = High | Class = No)\n",
    "- P(Attribute C = Mid | Class = Yes)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To compute these probabilities using Naive Bayes, we need to use Bayes' rule along with the assumption that the attributes are conditionally independent given the class.\n",
    "\n",
    "Let's denote the event \"Attribute A = Yes\" as A, \"Attribute B = Divorced\" as B, \"Attribute C = High\" as C, and \"Class = Yes\" as Y. Then, we have:\n",
    "\n",
    "P(A = Yes | Y = No) = (number of instances where A = Yes and Y = No) / (number of instances where Y = No)\n",
    "There are 4 instances where Y = No, and 2 of them have A = Yes. Therefore:\n",
    "\n",
    "P(A = Yes | Y = No) = 2/4 = 0.5\n",
    "\n",
    "P(B = Divorced | Y = Yes) = (number of instances where B = Divorced and Y = Yes) / (number of instances where Y = Yes)\n",
    "There are 3 instances where Y = Yes, and 1 of them has B = Divorced. Therefore:\n",
    "\n",
    "P(B = Divorced | Y = Yes) = 1/3 ≈ 0.333\n",
    "\n",
    "P(C = High | Y = No) = (number of instances where C = High and Y = No) / (number of instances where Y = No)\n",
    "There are 4 instances where Y = No, and 2 of them have C = High. Therefore:\n",
    "\n",
    "P(C = High | Y = No) = 2/4 = 0.5\n",
    "\n",
    "P(C = Mid | Y = Yes) = (number of instances where C = Mid and Y = Yes) / (number of instances where Y = Yes)\n",
    "There are 3 instances where Y = Yes, and 2 of them have C = Mid. Therefore:\n",
    "\n",
    "P(C = Mid | Y = Yes) = 2/3 ≈ 0.667\n",
    "\n",
    "Note that we assume conditional independence among the attributes, which means that P(A, B, C | Y) can be factorized as P(A | Y) * P(B | Y) * P(C | Y). This assumption may not hold in some cases, and the Naive Bayes model may not be the best choice for these situations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b) Classify the following unseen records:\n",
    "\n",
    "- (Yes, Married, Mid)\n",
    "- (No, Divorced, High)\n",
    "- (No, Single, High)\n",
    "- (No, Divorced, Low)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To classify the unseen records using Naive Bayes, we need to compute the posterior probability of each class given the attribute values and choose the class with the highest probability.\n",
    "\n",
    "Let's denote the first unseen record as R1 = (Yes, Married, Mid), the second as R2 = (No, Divorced, High), the third as R3 = (No, Single, High), and the fourth as R4 = (No, Divorced, Low).\n",
    "\n",
    "For each record, we need to compute P(Y = Yes | R) and P(Y = No | R), where R denotes the attribute values in the record.\n",
    "\n",
    "For R1 = (Yes, Married, Mid):\n",
    "P(Y = Yes | R1) ∝ P(R1 | Y = Yes) * P(Y = Yes) = P(Yes | Y = Yes) * P(Married | Y = Yes) * P(Mid | Y = Yes) * P(Y = Yes)\n",
    "\n",
    "= 0 * 0.333 * 0.667 * 0.3 ≈ 0\n",
    "\n",
    "P(Y = No | R1) ∝ P(R1 | Y = No) * P(Y = No) = P(Yes | Y = No) * P(Married | Y = No) * P(Mid | Y = No) * P(Y = No)\n",
    "\n",
    "= 0.5 * 0.5 * 0.5 * 0.7 = 0.0875\n",
    "\n",
    "Therefore, the Naive Bayes classifier would classify R1 as No.\n",
    "\n",
    "For R2 = (No, Divorced, High):\n",
    "P(Y = Yes | R2) ∝ P(R2 | Y = Yes) * P(Y = Yes) = P(No | Y = Yes) * P(Divorced | Y = Yes) * P(High | Y = Yes) * P(Y = Yes)\n",
    "\n",
    "= 0.333 * 1/3 * 0 * 0.3 ≈ 0\n",
    "\n",
    "P(Y = No | R2) ∝ P(R2 | Y = No) * P(Y = No) = P(No | Y = No) * P(Divorced | Y = No) * P(High | Y = No) * P(Y = No)\n",
    "\n",
    "= 0.8 * 0.25 * 0.5 * 0.7 = 0.07\n",
    "\n",
    "Therefore, the Naive Bayes classifier would classify R2 as No.\n",
    "\n",
    "For R3 = (No, Single, High):\n",
    "P(Y = Yes | R3) ∝ P(R3 | Y = Yes) * P(Y = Yes) = P(No | Y = Yes) * P(Single | Y = Yes) * P(High | Y = Yes) * P(Y = Yes)\n",
    "\n",
    "= 0.333 * 1/3 * 0 * 0.3 ≈ 0\n",
    "\n",
    "P(Y = No | R3) ∝ P(R3 | Y = No) * P(Y = No) = P(No | Y = No) * P(Single | Y = No) * P(High | Y = No) * P(Y = No)\n",
    "\n",
    "= 0.5 * 0.25 * 0.5 * 0.7 = 0.04375"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Evaluation\n",
    "\n",
    "a) Write a function to generate the confusion matrix for a list of actual classes and a list of predicted classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0]\n",
      " [0 0]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "actual_class = [\"Yes\", \"No\", \"No\", \"Yes\", \"No\", \"No\", \"Yes\", \"No\", \"No\", \"No\"]\n",
    "predicted_class = [\"Yes\", \"No\", \"Yes\", \"No\", \"No\", \"No\", \"Yes\", \"Yes\", \"Yes\", \"No\"]\n",
    "\n",
    "def confusion_matrix(actual, predicted):\n",
    "    classes = np.unique(actual)\n",
    "    n_classes = len(classes)\n",
    "    cm = np.zeros((n_classes, n_classes), dtype=int)\n",
    "    \n",
    "    for i in range(n_classes):\n",
    "        for j in range(n_classes):\n",
    "            cm[i, j] = np.sum((actual == classes[i]) & (predicted == classes[j]))\n",
    "    \n",
    "    return cm\n",
    "\n",
    "print(confusion_matrix(actual_class, predicted_class))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b) Assume you have the following Cost Matrix:\n",
    "\n",
    "|            | predicted = Y | predicted = N |\n",
    "|------------|---------------|---------------|\n",
    "| actual = Y |       -1      |       5       |\n",
    "| actual = N |        10     |       0       |\n",
    "\n",
    "What is the cost of the above classification?"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "cost = (number of true positives * cost of true positive) + \n",
    "       (number of false positives * cost of false positive) +\n",
    "       (number of true negatives * cost of true negative) +\n",
    "       (number of false negatives * cost of false negative)\n",
    "cost = (3 * -1) + (2 * 5) + (3 * 0) + (2 * 10)\n",
    "     = -3 + 10 + 0 + 20\n",
    "     = 27\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "c) Write a function that takes in the actual values, the predictions, and a cost matrix and outputs a cost. Test it on the above example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total cost: 0\n"
     ]
    }
   ],
   "source": [
    "def calculate_cost(actual, predicted, cost_matrix):\n",
    "    # Create a confusion matrix\n",
    "    conf_mat = confusion_matrix(actual, predicted)\n",
    "    \n",
    "    # Initialize total cost\n",
    "    total_cost = 0\n",
    "    \n",
    "    # Calculate cost of each type of classification\n",
    "    tp_cost = cost_matrix[0][0]\n",
    "    fp_cost = cost_matrix[0][1]\n",
    "    tn_cost = cost_matrix[1][1]\n",
    "    fn_cost = cost_matrix[1][0]\n",
    "    \n",
    "    # Calculate total cost using the formula\n",
    "    total_cost = (conf_mat[0][0] * tp_cost) + (conf_mat[0][1] * fp_cost) + (conf_mat[1][1] * tn_cost) + (conf_mat[1][0] * fn_cost)\n",
    "    \n",
    "    return total_cost\n",
    "\n",
    "# Define actual and predicted values\n",
    "actual = [\"Yes\", \"No\", \"No\", \"Yes\", \"No\", \"No\", \"Yes\", \"No\", \"No\", \"No\"]\n",
    "predicted = [\"Yes\", \"No\", \"Yes\", \"No\", \"No\", \"No\", \"Yes\", \"Yes\", \"Yes\", \"No\"]\n",
    "\n",
    "# Define cost matrix\n",
    "cost_matrix = [[-1, 5], [10, 0]]\n",
    "\n",
    "# Calculate cost using the function\n",
    "cost = calculate_cost(actual, predicted, cost_matrix)\n",
    "\n",
    "print(\"Total cost:\", cost)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "d) What is the difference between a testing set and a validation set?"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A validation set is used to choose the best hyperparameters for a model during training, while a testing set is used to evaluate the performance of a trained model on new, unseen data."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "e) What are some things you can do to handle the case where you have a highly imbalanced dataset (i.e. there are way more of one class than another). Describe both how you can provide better visibility into the failures of the model and how you can set your model training up for success."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To handle imbalanced datasets, it's important to use appropriate evaluation metrics, resample the data, use ensemble methods, generate synthetic data, and adjust class weights. These approaches can help to provide better visibility into the failures of the model and set the model training up for success."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
